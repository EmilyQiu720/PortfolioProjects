{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MongoDB Implementation of EzTraining Database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MongoDB Setup**\n",
    "Installed the required packages and setup MongoDB connection and select the database and collections which have been injected with artifical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pymongo[srv] in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (4.10.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from pymongo[srv]) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adith\\onedrive\\documents\\manalytics\\project\\215 project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pymongo 4.10.1 does not provide the extra 'srv'\n"
     ]
    }
   ],
   "source": [
    "! pip install pymongo[srv] pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to MongoDB (replace with your MongoDB URI if running on a remote server)\n",
    "client = MongoClient(\"mongodb+srv://adithyabhat:AvM4v7bkDCzgE9fo@cluster0.mi9cw.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "\n",
    "# Select the database and collections\n",
    "db = client[\"ez_training\"]\n",
    "payments = db[\"payments\"]\n",
    "workout_logs = db[\"workout_logs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query 1: Nested Aggregation for Revenue Insights**\n",
    "***Purpose:*** Calculate total revenue grouped by payment_method and further break it down by months. MongoDB’s pipeline for advanced analytics, avoiding complex nested SQL queries and improving maintainability as datasets grow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_amount payment_method month\n",
      "0            37          Check    01\n",
      "1            78         PayPal    02\n",
      "2            59         PayPal    03\n",
      "3            61     Debit Card    03\n",
      "4            69          Check    03\n"
     ]
    }
   ],
   "source": [
    "query1 = payments.aggregate([\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"parsed_date\": {\n",
    "                \"$dateFromString\": {\n",
    "                    \"dateString\": \"$payment_date\",\n",
    "                    \"format\": \"%m/%d/%Y\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"payment_method\": \"$payment_method\",\n",
    "                \"month\": {\"$dateToString\": {\"format\": \"%m\", \"date\": \"$parsed_date\"}}\n",
    "            },\n",
    "            \"total_amount\": {\"$sum\": \"$amount\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"_id.month\": 1}}  # Sort results by month\n",
    "])\n",
    "\n",
    "query1_result = list(query1)\n",
    "# Flatten the `_id` field\n",
    "for item in query1_result:\n",
    "    item.update(item.pop('_id'))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(query1_result)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query 2: Hierarchical Data Relationship Join**\n",
    "***Purpose:*** Join workout_logs and workout_sessions collections to find the top 3 workout programs (e.g., \"HIIT\", \"Yoga\") where members burned the most calories. This highlights MongoDB's $lookup functionality, which allows you to relate collections dynamically without rigid schema constraints. This is ideal for scaling data relationships without redesigning schemas, a common challenge in MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Program Type  total_calories\n",
      "0            Pilates             194\n",
      "1  Strength Training             160\n",
      "2             Cardio              51\n"
     ]
    }
   ],
   "source": [
    "query2 = workout_logs.aggregate([\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"workout_sessions\",\n",
    "            \"localField\": \"log_id\",\n",
    "            \"foreignField\": \"Workout_Log_ID\",\n",
    "            \"as\": \"session_details\"\n",
    "        }\n",
    "    },\n",
    "    {\"$unwind\": \"$session_details\"},  # Decompose arrays into individual documents\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$session_details.Program_type\",\n",
    "            \"total_calories\": {\"$sum\": \"$calories_burnt\"}\n",
    "        }\n",
    "    },\n",
    "    {\"$sort\": {\"total_calories\": -1}},  # Sort by total calories burned (descending)\n",
    "    {\"$limit\": 3}  # Top 3 programs\n",
    "])\n",
    "\n",
    "query2_result = list(query2)\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df2 = pd.DataFrame(query2_result, columns=[\"_id\", \"total_calories\"])\n",
    "df2.rename(columns={\"_id\": \"Program Type\"}, inplace=True)\n",
    "# Display the DataFrame\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advantages in scaling with MongoDB over MySQL:**\n",
    "**Future-Proofing the System:**\n",
    "MongoDB is designed for distributed systems and can handle high-growth scenarios seamlessly. A 100x increase in data is more manageable with MongoDB’s sharding and replication capabilities.\n",
    "\n",
    "**Real-Time Analytics:**\n",
    "MongoDB’s aggregation framework and fast lookups make it ideal for real-time insights, such as identifying top-performing workout programs or analyzing monthly payment trends.\n",
    "\n",
    "**Lower Operational Overhead:**\n",
    "MongoDB’s schema-less design reduces the need for time-consuming migrations, making it easier to adapt to changing business requirements as the client grows.\n",
    "\n",
    "**Flexibility for Evolving Data Models:**\n",
    "As the gym expands, new features (e.g., adding VR environments to sessions or new payment methods) can be added with minimal impact on existing collections.\n",
    "\n",
    "**Cost Efficiency:**\n",
    "Scaling MySQL often involves adding more powerful hardware to support increasing data loads. MongoDB, with its horizontal scaling capabilities, can add cheaper commodity servers to the cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
